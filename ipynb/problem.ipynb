{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline for Multi-Facility Location Problem\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load the provided `.pkl` files for train and test.\n",
        "2. Implement a simple baseline approach to place multiple facilities.\n",
        "3. Evaluate the average social cost.\n",
        "\n",
        "We assume:\n",
        "- We have `all_data_train.pkl` and `all_data_test.pkl` in a local `data/` folder.\n",
        "- A minimal baseline that places facilities at certain quantiles of the agent peaks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For simple numeric display\n",
        "pd.set_option('display.precision', 6)\n",
        "\n",
        "# Parameters:\n",
        "DATA_TRAIN_PATH = 'data/all_data_train.pkl'\n",
        "DATA_TEST_PATH = 'data/all_data_test.pkl'\n",
        "\n",
        "# Number of facilities:\n",
        "K = 2  # You can change this to 1, 3, etc.\n",
        "\n",
        "###########################################################\n",
        "# 1. LOAD DATA\n",
        "###########################################################\n",
        "with open(DATA_TRAIN_PATH, 'rb') as f:\n",
        "    data_train = pickle.load(f)\n",
        "with open(DATA_TEST_PATH, 'rb') as f:\n",
        "    data_test = pickle.load(f)\n",
        "\n",
        "print(\"Loaded train distributions:\", list(data_train.keys()))\n",
        "print(\"Loaded test distributions: \", list(data_test.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each entry in `data_train` / `data_test` is keyed by `(distribution, n)` where:\n",
        "- **distribution** ∈ \\{`uniform`, `normal`, `beta1`, `beta2`\\}\n",
        "- **n** is the number of agents.\n",
        "\n",
        "Each value is a dictionary containing:\n",
        "- **`peaks`**: shape `(1000, n)` — 1000 samples, each row is the real peaks of n agents.\n",
        "- **`misreports`**: shape `(10000, n)` — 10 misreports per sample (1000 * 10 = 10000). We won't use misreports here in this baseline, but it is available if you'd like to measure strategy-proofness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline Approach: Quantile Placement\n",
        "\n",
        "We'll define a very simple function that:\n",
        "1. Given an array of agent peaks (length `n`), sorts them.\n",
        "2. Chooses `K` quantile positions.\n",
        "3. Places each facility there.\n",
        "\n",
        "> For example, if `K=2`, we might place them at the 1/3 and 2/3 quantiles of the agent peaks. That is arbitrary but easy to implement.\n",
        "\n",
        "Then for each sample (each row in `peaks`), we compute the social cost = sum of each agent's distance to the nearest facility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def baseline_facility_location(peaks, K=2):\n",
        "    \"\"\"\n",
        "    Place K facilities at K equally spaced quantiles.\n",
        "    peaks: array of shape (n,) for a single sample.\n",
        "    \"\"\"\n",
        "    sorted_peaks = np.sort(peaks)\n",
        "    n = len(peaks)\n",
        "    facilities = []\n",
        "    for i in range(K):\n",
        "        # compute the quantile fraction\n",
        "        frac = (i + 1) / (K + 1)  \n",
        "        # find approximate quantile index\n",
        "        idx = int(frac * (n - 1))\n",
        "        facilities.append(sorted_peaks[idx])\n",
        "    return np.array(facilities)\n",
        "\n",
        "def compute_social_cost(peaks, facilities):\n",
        "    \"\"\"\n",
        "    Given an array of agent peaks (shape (n,)), and an array of facility positions, \n",
        "    compute the sum of distances from each agent to its nearest facility.\n",
        "    \"\"\"\n",
        "    # for each agent, distance to each facility, take min\n",
        "    distances = [ np.abs(p - facilities).min() for p in peaks ]\n",
        "    return np.sum(distances)\n",
        "\n",
        "def evaluate_baseline(peaks_array, K=2):\n",
        "    \"\"\"\n",
        "    Evaluate the baseline approach on an entire set of samples.\n",
        "    peaks_array: shape (num_samples, n)\n",
        "    \"\"\"\n",
        "    total_cost = 0.0\n",
        "    num_samples = peaks_array.shape[0]\n",
        "    for i in range(num_samples):\n",
        "        peaks = peaks_array[i]\n",
        "        facs = baseline_facility_location(peaks, K)\n",
        "        cost = compute_social_cost(peaks, facs)\n",
        "        total_cost += cost\n",
        "    return total_cost / num_samples  # average cost per sample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Evaluate on Train & Test\n",
        "\n",
        "We'll iterate over a small subset of distributions and agent counts to show how to compute the baseline social cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's pick some (distribution, n) keys to test.\n",
        "keys_to_check = [\n",
        "    ('uniform', 5),\n",
        "    ('normal', 5),\n",
        "    ('beta1', 5),\n",
        "    ('beta2', 5),\n",
        "    # You can add more if you want.\n",
        "]\n",
        "\n",
        "results = []\n",
        "for dist_n in keys_to_check:\n",
        "    if dist_n not in data_train:\n",
        "        continue\n",
        "    peaks_train = data_train[dist_n]['peaks']  # shape (1000, n)\n",
        "    peaks_test = data_test[dist_n]['peaks']    # shape (1000, n)\n",
        "\n",
        "    # Evaluate on train\n",
        "    avg_cost_train = evaluate_baseline(peaks_train, K=K)\n",
        "\n",
        "    # Evaluate on test\n",
        "    avg_cost_test = evaluate_baseline(peaks_test, K=K)\n",
        "\n",
        "    results.append({\n",
        "        'distribution': dist_n[0],\n",
        "        'n': dist_n[1],\n",
        "        'K': K,\n",
        "        'avg_cost_train': avg_cost_train,\n",
        "        'avg_cost_test': avg_cost_test\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The table above shows the **average cost** (distance) over 1000 samples in train and test sets, using this naive quantile-based placement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Notes\n",
        "- This code does **not** consider misreports, so it doesn't measure strategy-proofness.\n",
        "- The baseline we used is extremely simple. You can improve it by:\n",
        "  - Trying other quantile placements.\n",
        "  - Using a clustering method (like k-means on 1D) to find facility positions.\n",
        "  - Minimizing weighted cost if there are agent weights.\n",
        "  - Analyzing misreports to see if the facility location can be manipulated.\n"
      ]
    }
  ],
  "metadata": {
    "name": "baseline_multi_facility"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
